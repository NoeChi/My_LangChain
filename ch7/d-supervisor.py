from typing import Literal
from pydantic import BaseModel

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, MessagesState, START
from dotenv import load_dotenv
import os

load_dotenv(override=True)
api_key = os.getenv("OPENAI_API_KEY")

# =========================
# 1. Decision schema
# =========================
class SupervisorDecision(BaseModel):
    # basemodel ç”¨æ–¼å®šç¾©çµæ§‹åŒ–è¼¸å‡º
    next: Literal["researcher", "coder", "FINISH"]


# =========================
# 2. Models
# =========================
# ä¸€èˆ¬å°è©±æ¨¡å‹ï¼ˆçµ¦ researcher / coder ç”¨ï¼‰
llm = ChatOpenAI(model="gpt-4", temperature=0)

# Supervisor å°ˆç”¨ï¼ˆstructured outputï¼‰
supervisor_llm = llm.with_structured_output(SupervisorDecision)


# =========================
# 3. State
# =========================
class AgentState(MessagesState):
    # MessagesState å·²ç¶“æœ‰ç¹¼æ‰¿ messages æ¬„ä½äº†
    # MessagesState = messages: Annotated[list[BaseMessage], add_messages]
    next: Literal["researcher", "coder", "FINISH"]


# =========================
# 4. Supervisor node
# =========================
def supervisor(state: AgentState):
    print("\n========================")
    # ä½¿ç”¨ supervisor_llm ä¾†æ±ºå®šä¸‹ä¸€æ­¥è¡Œå‹•ï¼Œçµæ§‹åŒ–è¼¸å‡º
    print("ğŸ§‘â€ğŸ’¼ Supervisor evaluating state :", state)
    decision = supervisor_llm.invoke(
        [
            (
                "system",
                "You are a supervisor managing two workers: researcher and coder. "
                "Decide who should act next, or FINISH if the task is complete.",
            ),
            *state["messages"],
            (
                "system",
                "If the user request has been sufficiently addressed, choose FINISH. Otherwise choose exactly one of: researcher or coder.",
            ),
        ]
    )
    # æœƒè¼¸å‡ºnextæ¬„ä½ï¼Œæ±ºå®šä¸‹ä¸€æ­¥è¦å»å“ªå€‹ç¯€é»
    # æœƒè¼¸å‡º messages æ¬„ä½ï¼Œå‚³éçµ¦ä¸‹ä¸€å€‹ç¯€é»ä½¿ç”¨

    return {
        "next": decision.next,
    }


# =========================
# 5. Researcher node
# =========================
def researcher(state: AgentState):
    response = llm.invoke(
        [
            ("system", "You are a research assistant. Provide analysis and insights."),
            state["messages"][-1],
        ]
    )
    # åªæœƒè¼¸å‡º messages æ¬„ä½ï¼Œadd_messages reducer æœƒè‡ªå‹•åˆä½µ
    return {
        "messages": [response],
    }


# =========================
# 6. Coder node
# =========================
def coder(state: AgentState):
    response = llm.invoke(
        [
            ("system", "You are a coding assistant. Write code or technical solutions."),
            state["messages"][-1],
        ]
    )
    # åªæœƒè¼¸å‡º messages æ¬„ä½ï¼Œadd_messages reducer æœƒè‡ªå‹•åˆä½µ
    return {
        "messages": [response],
    }


# =========================
# 7. Build graph
# =========================
builder = StateGraph(AgentState)

builder.add_node("supervisor", supervisor)
builder.add_node("researcher", researcher)
builder.add_node("coder", coder)

builder.add_edge(START, "supervisor")

builder.add_conditional_edges(
    "supervisor",
    lambda state: state["next"],
    {"researcher": "researcher", "coder": "coder", "FINISH": "__end__"},
)

builder.add_edge("researcher", "supervisor")
builder.add_edge("coder", "supervisor")

graph = builder.compile()

# å„²å­˜ agent æ¶æ§‹åœ–
# png_data = graph.get_graph().draw_mermaid_png()
# with open("d-supervisor.png", "wb") as f:
#     f.write(png_data)
# print("æ¶æ§‹åœ–å·²å„²å­˜è‡³ d-supervisor.png")

# =========================
# 8. Example run
# =========================
initial_state = {
    "messages": [
        HumanMessage(
            content="What is the history of AI technique."
            # content="what is 4!"
        )
    ],
    "next": "supervisor",
}

for step in graph.stream(initial_state):
    print("\n========================")
    print("Step output:")
    print(step)

    if "messages" in step:
        last = step["messages"][-1]
        if isinstance(last, AIMessage):
            print("\nAgent response:")
            print(last.content)
